{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monochrome camera calibration\n",
    "One of the great disadvantages with using lenses is the distortion it introduces to the image. For vacation images, this is usually not a problem, but when we use the image to describe the physical surroundings it becomes important that the images are representative of the scene it captures. An easy way to get an indication of how distorted an image is by looking at what is supposed to be straight lines since they will appear curved. The following exercises you will be calibrating a camera to obtain a camera matrix such that you can undistort images from this camera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "The process of calibrating an image consists of mainly 3 steps: 1) find chessboard-corners in a dataset of images containing a chessboard. 2) Use the corner points to compute a camera matrix. 3) Use the camera matrix to undistort images.\n",
    "\n",
    "After setting some optimization parameters we can loop over all the images in the `imgs` folder and extract the checkerboard corners.\n",
    "\n",
    "Use any of the images in the folder `imgs` to extract the number of checkerboard corners there are on the checkerboard. Fill in the information in `nb_vertical` and `nb_horizontal` and look up the opencv `findChessboardCorners` function and implement it in the below code snippet ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nb_horizontal' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Bendik\\Documents\\Git\\Exercises-in-Perception-Group-2\\week 4 - Multiple View Geometry 2\\Bendik\\Exercises\\Exercise 1 - Monochrome camera calibration.ipynb Cell 4'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Bendik/Documents/Git/Exercises-in-Perception-Group-2/week%204%20-%20Multiple%20View%20Geometry%202/Bendik/Exercises/Exercise%201%20-%20Monochrome%20camera%20calibration.ipynb#ch0000003?line=0'>1</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Bendik/Documents/Git/Exercises-in-Perception-Group-2/week%204%20-%20Multiple%20View%20Geometry%202/Bendik/Exercises/Exercise%201%20-%20Monochrome%20camera%20calibration.ipynb#ch0000003?line=1'>2</a>\u001b[0m \u001b[39mImplement the number of vertical and horizontal corners\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Bendik/Documents/Git/Exercises-in-Perception-Group-2/week%204%20-%20Multiple%20View%20Geometry%202/Bendik/Exercises/Exercise%201%20-%20Monochrome%20camera%20calibration.ipynb#ch0000003?line=2'>3</a>\u001b[0m \u001b[39mnb_vertical = ...\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Bendik/Documents/Git/Exercises-in-Perception-Group-2/week%204%20-%20Multiple%20View%20Geometry%202/Bendik/Exercises/Exercise%201%20-%20Monochrome%20camera%20calibration.ipynb#ch0000003?line=3'>4</a>\u001b[0m \u001b[39mnb_horizontal = ...\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Bendik/Documents/Git/Exercises-in-Perception-Group-2/week%204%20-%20Multiple%20View%20Geometry%202/Bendik/Exercises/Exercise%201%20-%20Monochrome%20camera%20calibration.ipynb#ch0000003?line=4'>5</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Bendik/Documents/Git/Exercises-in-Perception-Group-2/week%204%20-%20Multiple%20View%20Geometry%202/Bendik/Exercises/Exercise%201%20-%20Monochrome%20camera%20calibration.ipynb#ch0000003?line=6'>7</a>\u001b[0m \u001b[39m# prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Bendik/Documents/Git/Exercises-in-Perception-Group-2/week%204%20-%20Multiple%20View%20Geometry%202/Bendik/Exercises/Exercise%201%20-%20Monochrome%20camera%20calibration.ipynb#ch0000003?line=7'>8</a>\u001b[0m objp \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros((nb_horizontal\u001b[39m*\u001b[39mnb_vertical,\u001b[39m3\u001b[39m), np\u001b[39m.\u001b[39mfloat32)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Bendik/Documents/Git/Exercises-in-Perception-Group-2/week%204%20-%20Multiple%20View%20Geometry%202/Bendik/Exercises/Exercise%201%20-%20Monochrome%20camera%20calibration.ipynb#ch0000003?line=8'>9</a>\u001b[0m objp[:,:\u001b[39m2\u001b[39m] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmgrid[\u001b[39m0\u001b[39m:nb_vertical,\u001b[39m0\u001b[39m:nb_horizontal]\u001b[39m.\u001b[39mT\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,\u001b[39m2\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Bendik/Documents/Git/Exercises-in-Perception-Group-2/week%204%20-%20Multiple%20View%20Geometry%202/Bendik/Exercises/Exercise%201%20-%20Monochrome%20camera%20calibration.ipynb#ch0000003?line=10'>11</a>\u001b[0m \u001b[39m# Arrays to store object points and image points from all the images.\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'nb_horizontal' is not defined"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Implement the number of vertical and horizontal corners\n",
    "nb_vertical = ...\n",
    "nb_horizontal = ...\n",
    "\"\"\"\n",
    "\n",
    "# prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "objp = np.zeros((nb_horizontal*nb_vertical,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:nb_vertical,0:nb_horizontal].T.reshape(-1,2)\n",
    "\n",
    "# Arrays to store object points and image points from all the images.\n",
    "objpoints = [] # 3d point in real world space\n",
    "imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "images = glob.glob('imgs/*.png')\n",
    "assert images\n",
    "\n",
    "\n",
    "for fname in images:\n",
    "    img = cv2.imread(fname)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    \"\"\"\n",
    "    Implement findChessboardCorners here\n",
    "    ret, corners = ...\n",
    "    \"\"\"\n",
    "\n",
    "    # If found, add object points, image points (after refining them)\n",
    "    if ret == True:\n",
    "        objpoints.append(objp)\n",
    "\n",
    "        imgpoints.append(corners)\n",
    "\n",
    "        # Draw and display the corners\n",
    "        img = cv2.drawChessboardCorners(img, (nb_vertical,nb_horizontal), corners,ret)\n",
    "        cv2.imshow('img',img)\n",
    "        cv2.waitKey(500)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the extracted corners we can obtain a camera matrix that contains the information needed to undistort images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, gray.shape[::-1], None, None)\n",
    "img = cv2.imread('imgs/1403709067387836928.png')\n",
    "h,  w = img.shape[:2]\n",
    "newcameramtx, roi = cv2.getOptimalNewCameraMatrix(mtx,dist,(w,h),1,(w,h))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last step is to actually undistort an image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# undistort\n",
    "dst = cv2.undistort(img, mtx, dist, None, newcameramtx)\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(18,18))\n",
    "ax[0].imshow(img[...,[2,1,0]])\n",
    "ax[0].set_title('Original image')\n",
    "ax[1].imshow(dst[...,[2,1,0]])\n",
    "ax[1].set_title('Undistorted image')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A refining step can be to crop the image such that it doesn't contain the large black areas at the edges of the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crop the image\n",
    "x,y,w,h = roi\n",
    "dst = dst[y:y+h, x:x+w]\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(dst[...,[2,1,0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
