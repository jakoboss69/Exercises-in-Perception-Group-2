{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weekly Project 5\n",
    "## Global Registration implementation.\n",
    "## Task 1\n",
    "Today your project is to implement a global registration algorithm.\n",
    "\n",
    "It should be able to roughly align two pointclouds.\n",
    "1. Implement global registration\n",
    "2. Can you fit **r1.pcd** and **r2.pcd**?\n",
    "3. Can you fit **car1.ply** and **car2.ply**?\n",
    "These are in the *global_registration* folder\n",
    "\n",
    "\n",
    "\n",
    "## Task 2 (Challange)\n",
    "Challanges attempt either or both:\n",
    "- Implement local registration.\n",
    "\n",
    "- Attempt to reconstruct the car from the images in *car_challange* folder.\n",
    "\n",
    "You can use the exercises from monday as a starting point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "# helper function for drawing if you want it to be more clear which is which set recolor=True\n",
    "def draw_registrations(source, target, transformation = None, recolor = False):\n",
    "    source_temp = copy.deepcopy(source)\n",
    "    target_temp = copy.deepcopy(target)\n",
    "    if(recolor):\n",
    "        source_temp.paint_uniform_color([1, 0.706, 0])\n",
    "        target_temp.paint_uniform_color([0, 0.651, 0.929])\n",
    "    if(transformation is not None):\n",
    "        source_temp.transform(transformation)\n",
    "    o3d.visualization.draw_geometries([source_temp, target_temp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'open3d.cpu.pybind.pipelines.registration' has no attribute 'compute_pfh_feature'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Bendik\\Documents\\Git\\Exercises-in-Perception-Group-2\\week 5\\bendik\\Weekly Project\\Weekly Project.ipynb Cell 3'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Bendik/Documents/Git/Exercises-in-Perception-Group-2/week%205/bendik/Weekly%20Project/Weekly%20Project.ipynb#ch0000002?line=17'>18</a>\u001b[0m sourceNormal \u001b[39m=\u001b[39m source\u001b[39m.\u001b[39mestimate_normals(search_param\u001b[39m=\u001b[39mo3d\u001b[39m.\u001b[39mgeometry\u001b[39m.\u001b[39mKDTreeSearchParamHybrid(radius\u001b[39m=\u001b[39mvoxel_size\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m, max_nn\u001b[39m=\u001b[39m\u001b[39m30\u001b[39m))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Bendik/Documents/Git/Exercises-in-Perception-Group-2/week%205/bendik/Weekly%20Project/Weekly%20Project.ipynb#ch0000002?line=18'>19</a>\u001b[0m targetNormal \u001b[39m=\u001b[39m target\u001b[39m.\u001b[39mestimate_normals(search_param\u001b[39m=\u001b[39mo3d\u001b[39m.\u001b[39mgeometry\u001b[39m.\u001b[39mKDTreeSearchParamHybrid(radius\u001b[39m=\u001b[39mvoxel_size\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m, max_nn\u001b[39m=\u001b[39m\u001b[39m30\u001b[39m))\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Bendik/Documents/Git/Exercises-in-Perception-Group-2/week%205/bendik/Weekly%20Project/Weekly%20Project.ipynb#ch0000002?line=20'>21</a>\u001b[0m sourcefpfh \u001b[39m=\u001b[39m o3d\u001b[39m.\u001b[39;49mpipelines\u001b[39m.\u001b[39;49mregistration\u001b[39m.\u001b[39;49mcompute_pfh_feature(source, o3d\u001b[39m.\u001b[39mgeometry\u001b[39m.\u001b[39mKDTreeSearchParamHybrid(radius\u001b[39m=\u001b[39mvoxel_size\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m, max_nn\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Bendik/Documents/Git/Exercises-in-Perception-Group-2/week%205/bendik/Weekly%20Project/Weekly%20Project.ipynb#ch0000002?line=21'>22</a>\u001b[0m targetfpfh \u001b[39m=\u001b[39m o3d\u001b[39m.\u001b[39mpipelines\u001b[39m.\u001b[39mregistration\u001b[39m.\u001b[39mcompute_pfh_feature(target, o3d\u001b[39m.\u001b[39mgeometry\u001b[39m.\u001b[39mKDTreeSearchParamHybrid(radius\u001b[39m=\u001b[39mvoxel_size\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m, max_nn\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m))\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'open3d.cpu.pybind.pipelines.registration' has no attribute 'compute_pfh_feature'"
     ]
    }
   ],
   "source": [
    "# source = o3d.io.read_point_cloud(\"global_registration/r1.pcd\")\n",
    "# target = o3d.io.read_point_cloud(\"global_registration/r2.pcd\")\n",
    "source = o3d.io.read_point_cloud(\"global_registration/car1.ply\")\n",
    "target = o3d.io.read_point_cloud(\"global_registration/car2.ply\")\n",
    "\n",
    "# Used for downsampling.\n",
    "voxel_size = 0.05\n",
    "\n",
    "# Show models side by side\n",
    "# draw_registrations(source, target)\n",
    "####\n",
    "# Downsample and find features here\n",
    "####\n",
    "\n",
    "source = source.voxel_down_sample(voxel_size=voxel_size)\n",
    "target = target.voxel_down_sample(voxel_size=voxel_size)\n",
    "\n",
    "sourceNormal = source.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=voxel_size*2, max_nn=30))\n",
    "targetNormal = target.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=voxel_size*2, max_nn=30))\n",
    "\n",
    "sourcefpfh = o3d.pipelines.registration.compute_fpfh_feature(source, o3d.geometry.KDTreeSearchParamHybrid(radius=voxel_size*2, max_nn=100))\n",
    "targetfpfh = o3d.pipelines.registration.compute_fpfh_feature(target, o3d.geometry.KDTreeSearchParamHybrid(radius=voxel_size*2, max_nn=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "####\n",
    "# Call RANSAC here\n",
    "####\n",
    "\n",
    "point_to_point =  o3d.pipelines.registration.TransformationEstimationPointToPoint(False)\n",
    "point_to_plane =  o3d.pipelines.registration.TransformationEstimationPointToPlane()\n",
    "\n",
    "corr_length = 0.9\n",
    "distance_threshold = voxel_size * 1.5\n",
    "\n",
    "c0 = o3d.pipelines.registration.CorrespondenceCheckerBasedOnEdgeLength(corr_length)\n",
    "c1 = o3d.pipelines.registration.CorrespondenceCheckerBasedOnDistance(distance_threshold)\n",
    "c2 = o3d.pipelines.registration.CorrespondenceCheckerBasedOnNormal(0.095)\n",
    "\n",
    "checker_list = [c0,c1,c2]\n",
    "\n",
    "ransac_result = o3d.pipelines.registration.registration_ransac_based_on_feature_matching(\n",
    "    source, target, \n",
    "    sourcefpfh, targetfpfh, \n",
    "    True,\n",
    "    distance_threshold,\n",
    "    point_to_point,\n",
    "    checkers = checker_list)\n",
    "\n",
    "draw_registrations(source, target, ransac_result.transformation, True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
